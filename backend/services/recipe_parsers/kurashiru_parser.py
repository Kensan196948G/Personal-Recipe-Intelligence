"""
ã‚¯ãƒ©ã‚·ãƒ« ãƒ‘ãƒ¼ã‚µãƒ¼

ã‚¯ãƒ©ã‚·ãƒ« ãƒ¬ã‚·ãƒ”ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
"""

import re
import json
from typing import Dict, Any, Optional
from bs4 import BeautifulSoup
import logging

from backend.services.external_recipe_service import RecipeParser, RecipeData

logger = logging.getLogger(__name__)


class KurashiruParser(RecipeParser):
    """ã‚¯ãƒ©ã‚·ãƒ« ãƒ¬ã‚·ãƒ”ãƒ‘ãƒ¼ã‚µãƒ¼"""

    def can_parse(self, url: str) -> bool:
        """ã‚¯ãƒ©ã‚·ãƒ« URLã‹åˆ¤å®š"""
        domain = self.extract_domain(url)
        return "kurashiru.com" in domain

    async def parse(self, html: str, url: str) -> RecipeData:
        """ã‚¯ãƒ©ã‚·ãƒ« HTMLã‚’è§£æ"""
        soup = BeautifulSoup(html, "html.parser")

        # JSON-LD ã‹ã‚‰æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        recipe_data = self._extract_json_ld(soup)
        if recipe_data:
            return self._parse_json_ld(recipe_data, url)

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: HTML ã‹ã‚‰ç›´æ¥æŠ½å‡º
        return self._parse_html(soup, url)

    def _extract_json_ld(self, soup: BeautifulSoup) -> Optional[Dict[str, Any]]:
        """JSON-LD æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        try:
            scripts = soup.find_all("script", type="application/ld+json")
            for script_tag in scripts:
                data = json.loads(script_tag.string)
                if isinstance(data, list):
                    for item in data:
                        if item.get("@type") == "Recipe":
                            return item
                elif data.get("@type") == "Recipe":
                    return data
        except Exception as e:
            logger.warning(f"Failed to extract JSON-LD: {e}")
        return None

    def _parse_json_ld(self, data: Dict[str, Any], url: str) -> RecipeData:
        """JSON-LD ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ RecipeData ã‚’ç”Ÿæˆ"""
        # ææ–™ã‚’è§£æ
        ingredients = []
        for ingredient_text in data.get("recipeIngredient", []):
            parsed = self._parse_ingredient(ingredient_text)
            ingredients.append(parsed)

        # æ‰‹é †ã‚’è§£æ
        steps = []
        instructions = data.get("recipeInstructions", [])
        if isinstance(instructions, list):
            for step in instructions:
                if isinstance(step, dict):
                    steps.append(step.get("text", ""))
                else:
                    steps.append(str(step))
        elif isinstance(instructions, str):
            steps = [instructions]

        # èª¿ç†æ™‚é–“
        cook_time = self._parse_duration(data.get("cookTime", ""))
        prep_time = self._parse_duration(data.get("prepTime", ""))
        total_time = self._parse_duration(data.get("totalTime", ""))

        cooking_time = (
            total_time or f"{prep_time} + {cook_time}"
            if prep_time and cook_time
            else cook_time
        )

        return RecipeData(
            title=data.get("name", ""),
            ingredients=ingredients,
            steps=steps,
            description=data.get("description", ""),
            servings=str(data.get("recipeYield", "")),
            cooking_time=cooking_time,
            image_url=self._extract_image_url(data.get("image")),
            source_url=url,
            tags=data.get("keywords", "").split(",") if data.get("keywords") else [],
            author=self._extract_author(data.get("author")),
        )

    def _parse_html(self, soup: BeautifulSoup, url: str) -> RecipeData:
        """HTML ã‹ã‚‰ç›´æ¥ãƒ¬ã‚·ãƒ”ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        # ã‚¿ã‚¤ãƒˆãƒ«
        title_tag = soup.find("h1", class_="recipe-title") or soup.find("h1")
        title = title_tag.get_text(strip=True) if title_tag else "ç„¡é¡Œã®ãƒ¬ã‚·ãƒ”"

        # ææ–™
        ingredients = []
        ingredient_section = soup.find("div", class_="ingredient-list") or soup.find(
            "section", class_="ingredients"
        )
        if ingredient_section:
            for item in ingredient_section.find_all("li"):
                text = item.get_text(strip=True)
                parsed = self._parse_ingredient(text)
                ingredients.append(parsed)

        # æ‰‹é †
        steps = []
        steps_section = soup.find("div", class_="steps") or soup.find(
            "section", class_="instructions"
        )
        if steps_section:
            for step in steps_section.find_all("li"):
                steps.append(step.get_text(strip=True))

        # ç”»åƒ
        image_url = None
        image_tag = soup.find("img", class_="recipe-image") or soup.find(
            "meta", property="og:image"
        )
        if image_tag:
            image_url = image_tag.get("src") or image_tag.get("content")

        # èª¬æ˜
        description_tag = soup.find("p", class_="description") or soup.find(
            "meta", property="og:description"
        )
        description = None
        if description_tag:
            description = (
                description_tag.get_text(strip=True)
                if hasattr(description_tag, "get_text")
                else description_tag.get("content")
            )

        return RecipeData(
            title=title,
            ingredients=ingredients,
            steps=steps,
            description=description,
            image_url=image_url,
            source_url=url,
            tags=["kurashiru", "ã‚¯ãƒ©ã‚·ãƒ«"],
        )

    def _parse_ingredient(self, text: str) -> Dict[str, str]:
        """ææ–™ãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æ"""
        # ä¾‹: "ç‰ã­ã 1å€‹", "ç ‚ç³– å¤§ã•ã˜2"
        match = re.match(r"^(.+?)\s+(.+)$", text.strip())
        if match:
            name = match.group(1)
            amount_text = match.group(2)

            # å˜ä½ã‚’æŠ½å‡º
            unit_match = re.search(
                r"(å€‹|æœ¬|æš|ç‰‡|g|kg|ml|L|cc|ã‚«ãƒƒãƒ—|å¤§ã•ã˜|å°ã•ã˜|é©é‡|å°‘ã€…)",
                amount_text,
            )
            if unit_match:
                unit = unit_match.group(1)
                amount = amount_text.replace(unit, "").strip()
            else:
                unit = ""
                amount = amount_text

            return {"name": name, "amount": amount, "unit": unit}
        else:
            return {"name": text, "amount": "", "unit": ""}

    def _parse_duration(self, duration: str) -> str:
        """ISO 8601 duration ã‚’åˆ†ã«å¤‰æ›"""
        if not duration:
            return ""

        # PT1H30M -> 1æ™‚é–“30åˆ† (æœ€ã‚‚è¤‡é›‘ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å…ˆã«ãƒã‚§ãƒƒã‚¯)
        match = re.search(r"PT(\d+)H(\d+)M", duration)
        if match:
            return f"{match.group(1)}æ™‚é–“{match.group(2)}åˆ†"

        # PT30M -> 30åˆ†
        match = re.search(r"PT(\d+)M", duration)
        if match:
            return f"{match.group(1)}åˆ†"

        # PT1H -> 1æ™‚é–“
        match = re.search(r"PT(\d+)H", duration)
        if match:
            return f"{match.group(1)}æ™‚é–“"

        return duration

    def _extract_image_url(self, image_data: Any) -> Optional[str]:
        """ç”»åƒURLã‚’æŠ½å‡º"""
        if isinstance(image_data, str):
            return image_data
        elif isinstance(image_data, dict):
            return image_data.get("url")
        elif isinstance(image_data, list) and len(image_data) > 0:
            return (
                image_data[0]
                if isinstance(image_data[0], str)
                else image_data[0].get("url")
            )
        return None

    def _extract_author(self, author_data: Any) -> Optional[str]:
        """è‘—è€…åã‚’æŠ½å‡º"""
        if isinstance(author_data, str):
            return author_data
        elif isinstance(author_data, dict):
            return author_data.get("name")
        return None

    def site_info(self) -> Dict[str, str]:
        """ã‚µã‚¤ãƒˆæƒ…å ±ã‚’è¿”ã™"""
        return {
            "name": "ã‚¯ãƒ©ã‚·ãƒ«",
            "domain": "kurashiru.com",
            "icon": "ğŸ“±",
        }
