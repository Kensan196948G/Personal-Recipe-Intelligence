"""
DELISH KITCHEN ãƒ‘ãƒ¼ã‚µãƒ¼

DELISH KITCHEN ãƒ¬ã‚·ãƒ”ãƒšãƒ¼ã‚¸ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
"""

import re
import json
from typing import Dict, Any, Optional
from bs4 import BeautifulSoup
import logging

from backend.services.external_recipe_service import RecipeParser, RecipeData

logger = logging.getLogger(__name__)


class DelishKitchenParser(RecipeParser):
    """DELISH KITCHEN ãƒ¬ã‚·ãƒ”ãƒ‘ãƒ¼ã‚µãƒ¼"""

    def can_parse(self, url: str) -> bool:
        """DELISH KITCHEN URLã‹åˆ¤å®š"""
        domain = self.extract_domain(url)
        return "delishkitchen.tv" in domain

    async def parse(self, html: str, url: str) -> RecipeData:
        """DELISH KITCHEN HTMLã‚’è§£æ"""
        soup = BeautifulSoup(html, "html.parser")

        # JSON-LD ã‹ã‚‰æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        recipe_data = self._extract_json_ld(soup)
        if recipe_data:
            return self._parse_json_ld(recipe_data, url)

        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: HTML ã‹ã‚‰ç›´æ¥æŠ½å‡º
        return self._parse_html(soup, url)

    def _extract_json_ld(self, soup: BeautifulSoup) -> Optional[Dict[str, Any]]:
        """JSON-LD æ§‹é€ åŒ–ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        try:
            scripts = soup.find_all("script", type="application/ld+json")
            for script_tag in scripts:
                data = json.loads(script_tag.string)
                if isinstance(data, list):
                    for item in data:
                        if item.get("@type") == "Recipe":
                            return item
                elif data.get("@type") == "Recipe":
                    return data
        except Exception as e:
            logger.warning(f"Failed to extract JSON-LD: {e}")
        return None

    def _parse_json_ld(self, data: Dict[str, Any], url: str) -> RecipeData:
        """JSON-LD ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ RecipeData ã‚’ç”Ÿæˆ"""
        # ææ–™ã‚’è§£æ
        ingredients = []
        for ingredient_text in data.get("recipeIngredient", []):
            parsed = self._parse_ingredient(ingredient_text)
            ingredients.append(parsed)

        # æ‰‹é †ã‚’è§£æ
        steps = []
        instructions = data.get("recipeInstructions", [])
        if isinstance(instructions, list):
            for step in instructions:
                if isinstance(step, dict):
                    # HowToStep å½¢å¼
                    text = step.get("text") or step.get("name", "")
                    if text:
                        steps.append(text)
                else:
                    steps.append(str(step))
        elif isinstance(instructions, str):
            steps = [instructions]

        # èª¿ç†æ™‚é–“
        cook_time = self._parse_duration(data.get("cookTime", ""))
        prep_time = self._parse_duration(data.get("prepTime", ""))
        total_time = self._parse_duration(data.get("totalTime", ""))

        cooking_time = total_time or (
            f"{prep_time} + {cook_time}" if prep_time and cook_time else cook_time
        )

        # ã‚«ãƒ†ã‚´ãƒªãƒ¼ãƒ»ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        tags = []
        if data.get("recipeCategory"):
            tags.append(data["recipeCategory"])
        if data.get("keywords"):
            keywords = data["keywords"]
            if isinstance(keywords, str):
                tags.extend([k.strip() for k in keywords.split(",")])
            elif isinstance(keywords, list):
                tags.extend(keywords)

        return RecipeData(
            title=data.get("name", ""),
            ingredients=ingredients,
            steps=steps,
            description=data.get("description", ""),
            servings=str(data.get("recipeYield", "")),
            cooking_time=cooking_time,
            image_url=self._extract_image_url(data.get("image")),
            source_url=url,
            tags=tags,
            author=self._extract_author(data.get("author")),
        )

    def _parse_html(self, soup: BeautifulSoup, url: str) -> RecipeData:
        """HTML ã‹ã‚‰ç›´æ¥ãƒ¬ã‚·ãƒ”ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º"""
        # ã‚¿ã‚¤ãƒˆãƒ«
        title_tag = soup.find("h1", class_="recipe-title") or soup.find("h1")
        title = title_tag.get_text(strip=True) if title_tag else "ç„¡é¡Œã®ãƒ¬ã‚·ãƒ”"

        # ææ–™
        ingredients = []
        ingredient_section = soup.find("div", class_="ingredients") or soup.find(
            "section", class_="recipe-ingredients"
        )
        if ingredient_section:
            for item in ingredient_section.find_all("li"):
                text = item.get_text(strip=True)
                parsed = self._parse_ingredient(text)
                ingredients.append(parsed)

        # æ‰‹é †
        steps = []
        steps_section = soup.find("div", class_="recipe-steps") or soup.find(
            "section", class_="instructions"
        )
        if steps_section:
            for step in steps_section.find_all("li"):
                step_text = step.get_text(strip=True)
                # æ‰‹é †ç•ªå·ã‚’å‰Šé™¤
                step_text = re.sub(r"^\d+\.\s*", "", step_text)
                steps.append(step_text)

        # ç”»åƒ
        image_url = None
        image_tag = soup.find("img", class_="recipe-image") or soup.find(
            "meta", property="og:image"
        )
        if image_tag:
            image_url = image_tag.get("src") or image_tag.get("content")

        # èª¬æ˜
        description_tag = soup.find("p", class_="description") or soup.find(
            "meta", property="og:description"
        )
        description = None
        if description_tag:
            description = (
                description_tag.get_text(strip=True)
                if hasattr(description_tag, "get_text")
                else description_tag.get("content")
            )

        return RecipeData(
            title=title,
            ingredients=ingredients,
            steps=steps,
            description=description,
            image_url=image_url,
            source_url=url,
            tags=["delish-kitchen"],
        )

    def _parse_ingredient(self, text: str) -> Dict[str, str]:
        """ææ–™ãƒ†ã‚­ã‚¹ãƒˆã‚’è§£æ"""
        # ä¾‹: "ç‰ã­ã 1å€‹", "ç ‚ç³– å¤§ã•ã˜2", "å¡© å°‘ã€…"
        match = re.match(r"^(.+?)\s+(.+)$", text.strip())
        if match:
            name = match.group(1)
            amount_text = match.group(2)

            # å˜ä½ã‚’æŠ½å‡º
            unit_match = re.search(
                r"(å€‹|æœ¬|æš|ç‰‡|åˆ‡ã‚Œ|g|kg|ml|L|dl|cc|ã‚«ãƒƒãƒ—|å¤§ã•ã˜|å°ã•ã˜|é©é‡|å°‘ã€…|ã²ã¨ã¤ã¾ã¿)",
                amount_text,
            )
            if unit_match:
                unit = unit_match.group(1)
                amount = amount_text.replace(unit, "").strip()
            else:
                unit = ""
                amount = amount_text

            return {"name": name, "amount": amount, "unit": unit}
        else:
            return {"name": text, "amount": "", "unit": ""}

    def _parse_duration(self, duration: str) -> str:
        """ISO 8601 duration ã‚’åˆ†ã«å¤‰æ›"""
        if not duration:
            return ""

        # PT30M -> 30åˆ†
        match = re.search(r"PT(\d+)M", duration)
        if match:
            return f"{match.group(1)}åˆ†"

        # PT1H -> 1æ™‚é–“
        match = re.search(r"PT(\d+)H", duration)
        if match:
            return f"{match.group(1)}æ™‚é–“"

        # PT1H30M -> 1æ™‚é–“30åˆ†
        match = re.search(r"PT(\d+)H(\d+)M", duration)
        if match:
            return f"{match.group(1)}æ™‚é–“{match.group(2)}åˆ†"

        return duration

    def _extract_image_url(self, image_data: Any) -> Optional[str]:
        """ç”»åƒURLã‚’æŠ½å‡º"""
        if isinstance(image_data, str):
            return image_data
        elif isinstance(image_data, dict):
            return image_data.get("url")
        elif isinstance(image_data, list) and len(image_data) > 0:
            return (
                image_data[0]
                if isinstance(image_data[0], str)
                else image_data[0].get("url")
            )
        return None

    def _extract_author(self, author_data: Any) -> Optional[str]:
        """è‘—è€…åã‚’æŠ½å‡º"""
        if isinstance(author_data, str):
            return author_data
        elif isinstance(author_data, dict):
            return author_data.get("name")
        return None

    def site_info(self) -> Dict[str, str]:
        """ã‚µã‚¤ãƒˆæƒ…å ±ã‚’è¿”ã™"""
        return {
            "name": "DELISH KITCHEN",
            "domain": "delishkitchen.tv",
            "icon": "ğŸ½ï¸",
        }
